# 第 3 部分：AI 中的工具是什么？

在上一部分中，我们讨论了不同类型的智能体，从基于规则的到完全自主的，以及合适的自主程度如何取决于你要解决的问题。

但无论智能体多么简单或复杂，它们都有一个共同特征：

> **它们依赖工具来执行操作。**

---

## AI 中的“工具”是什么？

在智能体式（Agentic）AI 的语境下，“工具”指的是 LLM 可以调用的外部能力，例如：
- API
- 数据库查询
- 内部服务
- 第三方系统
- 用代码编写的内部函数

它们把 LLM 从一个只会**说话**的模型，变成一个能够**做事**的系统。

请记住，单独的 LLM 是**无状态的**，**无法访问实时系统**，也**无法执行操作**。

---

## 但给它们工具后，它们可以：
- 从你的内部系统获取数据
- 触发事件（例如，发送电子邮件、创建 JIRA 工单）
- 访问结构化数据，如日历、仪表板或 CRM 系统
- 基于业务规则运行预编写的逻辑

这就是从“生成内容”走向“执行任务”的关键一步。

---

## 工具为何重要

1. **它们解锁了执行能力**
   没有工具，你的智能体只是一个提供建议的助手。
   有了工具，它可以端到端地完成工作流。

2. **它们提高了准确性**
   LLM 可以直接向正确的系统查询，而不是凭空捏造——
   “订单的实际状态是什么？”而不是编造一个延迟原因。

3. **它们让你能够控制风险**
   你定义了可以暴露的内容。LLM 只能在你注册的工具范围内操作。

4. **它们实现了组合性**
   如果你想将 CRM、日历和电子邮件栈组合成一个助手，
   你可以将每个都暴露为工具，让 LLM 来协调它们。

---

## 逐步示例：使用工具完成端到端智能体任务

**任务：**
> “告知客户他们的订单已延迟，并提供新的交货时间。”

**系统如何使用工具工作：**

**输入** — 人类输入：
_“嘿，你能通知约翰他的订单已延迟，并重新安排到明天吗？”_

**规划** — LLM 将其分解为：
- 检查订单状态
- 如果延迟，检查交货时段
- 起草电子邮件
- 发送电子邮件
- 记录交互

**工具调用：**
```text
get_order_status(order_id=12345)
get_available_slots(date=today+1)
send_email(to=john@example.com, content=...)
log_event(event_type="reschedule", status="completed")
```

**文本生成** — LLM 撰写消息：
_“嗨，约翰，只是想通知你你的订单已延迟。我们已将其重新安排到明天。感谢你的耐心等待。”_

**执行** — 系统运行操作，记录输出，并可选地向仪表板发送状态更新。

---

## 工作原理（可视化）
<img width="808" height="357" alt="image" src="https://github.com/user-attachments/assets/f7ce3097-873f-4519-b7ba-30b80785deae" />


以下是具体过程：

1. 用户提出问题或给出任务。
2. LLM 理解需要做什么，并（在需要时）规划下一步行动。
3. 系统将 LLM 的输出解析/约束为结构化的工具调用（如 `get_order_status(order_id=12345)`）。
4. 智能体调用正确的工具——API、数据库查询或内部函数。
5. 工具返回结果——这通常被称为**观测（observation）**。
6. LLM 查看结果，决定缺少什么或下一步该做什么。
7. 这个循环继续，直到它有足够的信息生成最终答案或完成任务。

LLM 使用每个工具的结果来指导其下一个决策。

---

**重要提醒：**
LLM 本身仍然只是生成文本。
这些文本会被系统当作工具调用来执行；执行结果再回传给 LLM——形成“推理 → 行动 → 反思”的闭环（**这就是智能体系统的核心循环**）。

这种结构被 LangChain、CrewAI、AutoGen 等框架以及生产团队中的自定义编排设置所使用。

---

## 什么让工具对 LLM 可用？

要将工具注册到智能体系统中，你通常需要定义：
- **名称**（例如，`create_meeting`）
- **描述**（让模型知道何时使用它）
- **输入参数**（和类型）
- **输出结构**（让模型可以使用结果）

这些元数据使 LLM 能够推理使用哪个工具以及如何使用。

---

## 关于解析和结构化输出的说明

解析器在将 LLM 的响应转换为结构化工具调用方面起着关键作用——这是系统可以可靠执行的操作（如 `get_order_status(order_id=12345)`）。

但在许多现代设置中，你并不总是需要单独的解析器。
大多数流行的 LLM，特别是那些为工具调用设计的，可以直接生成结构化输出——如 JSON 或函数调用——可以直接被你的后端使用。

同样，设计良好的工具返回结构化数据，使 LLM 更容易推理下一步该做什么。

**双方的结构**（输入和输出）使智能体循环**健壮、可追溯且适用于生产环境**。

---

## 要点总结

如果你之前构建或使用过 API，这一切会感觉很熟悉。
但如果你不是来自这个领域，不要过度纠结于细节。

只需记住：
> AI 模型本身可以**理解**和**生成**。
> 当它们与软件、工具、API 和内部系统连接时——它们实际上可以**做事情**。

---

在下一部分中，我们将学习**检索增强生成（RAG）**——它是什么、何时使用以及如何自然地作为记忆或上下文层融入 Agentic 管道。